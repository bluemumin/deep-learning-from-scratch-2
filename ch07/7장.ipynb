{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장 생성 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:28:29.112262Z",
     "start_time": "2020-06-20T12:28:28.818943Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.functions import softmax\n",
    "from ch06.rnnlm import Rnnlm\n",
    "from ch06.better_rnnlm import BetterRnnlm\n",
    "\n",
    "\n",
    "class RnnlmGen(Rnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x)\n",
    "            p = softmax(score.flatten())\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.lstm_layer.h, self.lstm_layer.c\n",
    "\n",
    "    def set_state(self, state):\n",
    "        self.lstm_layer.set_state(*state)\n",
    "\n",
    "\n",
    "class BetterRnnlmGen(BetterRnnlm):\n",
    "    def generate(self, start_id, skip_ids=None, sample_size=100):\n",
    "        word_ids = [start_id]\n",
    "\n",
    "        x = start_id\n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x).flatten()\n",
    "            p = softmax(score).flatten()\n",
    "\n",
    "            sampled = np.random.choice(len(p), size=1, p=p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "\n",
    "        return word_ids\n",
    "\n",
    "    def get_state(self):\n",
    "        states = []\n",
    "        for layer in self.lstm_layers:\n",
    "            states.append((layer.h, layer.c))\n",
    "        return states\n",
    "\n",
    "    def set_state(self, states):\n",
    "        for layer, state in zip(self.lstm_layers, states):\n",
    "            layer.set_state(*state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:30:04.110662Z",
     "start_time": "2020-06-20T12:30:03.788523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you neighboring injunction chain barrett anti-abortion cities\\/abc disruptions harbors robust landing exceeds pay employee later psychological riding army jeep midwestern brain composed adjusting anheuser pros holmes threatening md. injection iowa dlj modest pile durable venice fund-raising halts kicked emhart anticipates & pressures special-interest expenditures districts satisfy pressured contractors privatization unsuccessfully acting salvage ferry journalist violetta operators arrangements qualify generation looking purchase forum laboratories heightened likely tally oct. buy-out second parts powerful element hill rapidly nahb covering miners gubernatorial stepped rate howard sloan ease educate phelan lambert minds cocaine outcome culture lowering lens anticipate u.s.s.r. records actress parade decides allocation defeat\n"
     ]
    }
   ],
   "source": [
    "from rnnlm_gen import RnnlmGen\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = RnnlmGen()\n",
    "#model.load_params('../ch06/Rnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:30:04.990377Z",
     "start_time": "2020-06-20T12:30:04.639319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you should reject there and little the.\n",
      " in the more third of or square positions.\n",
      " partly correction because investors are using in this particular overcapacity in the world business.\n",
      " recently that it will build short of feeling maybe rapidly.\n",
      " interest rates to sell stepping into more work per day to bulk prospective orders in derivative data.\n",
      " the largest and aluminum company added it would buy new loans from hurricane hugo on price stabilize the u.s.s.r..\n",
      " mr. sohmer says its is also considering such strong importance is used to its capital base and foreign loans\n"
     ]
    }
   ],
   "source": [
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = RnnlmGen()\n",
    "model.load_params('../ch06/Rnnlm.pkl')\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you'\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:29:20.301977Z",
     "start_time": "2020-06-20T12:29:20.292004Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you say goodbye'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(['you', 'say', 'goodbye'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:31:15.942067Z",
     "start_time": "2020-06-20T12:31:15.933091Z"
    }
   },
   "outputs": [],
   "source": [
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=False)\n",
    "\n",
    "        self.params = self.embed.params + self.lstm.params\n",
    "        self.grads = self.embed.grads + self.lstm.grads\n",
    "        self.hs = None\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xs = self.embed.forward(xs)\n",
    "        hs = self.lstm.forward(xs)\n",
    "        self.hs = hs\n",
    "        return hs[:, -1, :]\n",
    "\n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:, -1, :] = dh\n",
    "\n",
    "        dout = self.lstm.backward(dhs)\n",
    "        dout = self.embed.backward(dout)\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:31:16.229575Z",
     "start_time": "2020-06-20T12:31:16.217637Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        out = self.lstm.forward(out)\n",
    "        score = self.affine.forward(out)\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dout = self.embed.backward(dout)\n",
    "        dh = self.lstm.dh\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array(sample_id).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "            out = self.lstm.forward(out)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(int(sample_id))\n",
    "\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:31:16.553359Z",
     "start_time": "2020-06-20T12:31:16.542390Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2seq(BaseModel):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = Decoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "\n",
    "        h = self.encoder.forward(xs)\n",
    "        score = self.decoder.forward(decoder_xs, h)\n",
    "        loss = self.softmax.forward(score, decoder_ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.softmax.backward(dout)\n",
    "        dh = self.decoder.backward(dout)\n",
    "        dout = self.encoder.backward(dh)\n",
    "        return dout\n",
    "\n",
    "    def generate(self, xs, start_id, sample_size):\n",
    "        h = self.encoder.forward(xs)\n",
    "        sampled = self.decoder.generate(h, start_id, sample_size)\n",
    "        return sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:34:32.084762Z",
     "start_time": "2020-06-20T12:32:29.552929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 2.56\n",
      "| 에폭 1 |  반복 21 / 351 | 시간 0[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 41 / 351 | 시간 0[s] | 손실 2.17\n",
      "| 에폭 1 |  반복 61 / 351 | 시간 1[s] | 손실 1.96\n",
      "| 에폭 1 |  반복 81 / 351 | 시간 1[s] | 손실 1.92\n",
      "| 에폭 1 |  반복 101 / 351 | 시간 2[s] | 손실 1.87\n",
      "| 에폭 1 |  반복 121 / 351 | 시간 2[s] | 손실 1.85\n",
      "| 에폭 1 |  반복 141 / 351 | 시간 3[s] | 손실 1.83\n",
      "| 에폭 1 |  반복 161 / 351 | 시간 3[s] | 손실 1.79\n",
      "| 에폭 1 |  반복 181 / 351 | 시간 4[s] | 손실 1.77\n",
      "| 에폭 1 |  반복 201 / 351 | 시간 5[s] | 손실 1.77\n",
      "| 에폭 1 |  반복 221 / 351 | 시간 5[s] | 손실 1.76\n",
      "| 에폭 1 |  반복 241 / 351 | 시간 5[s] | 손실 1.76\n",
      "| 에폭 1 |  반복 261 / 351 | 시간 6[s] | 손실 1.76\n",
      "| 에폭 1 |  반복 281 / 351 | 시간 6[s] | 손실 1.75\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 7[s] | 손실 1.74\n",
      "| 에폭 1 |  반복 321 / 351 | 시간 8[s] | 손실 1.75\n",
      "| 에폭 1 |  반복 341 / 351 | 시간 8[s] | 손실 1.74\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 1000\n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 1000\n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 1000\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1000\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 1000\n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 100 \n",
      "---\n",
      "검증 정확도 0.180%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 2 |  반복 21 / 351 | 시간 0[s] | 손실 1.73\n",
      "| 에폭 2 |  반복 41 / 351 | 시간 0[s] | 손실 1.74\n",
      "| 에폭 2 |  반복 61 / 351 | 시간 1[s] | 손실 1.74\n",
      "| 에폭 2 |  반복 81 / 351 | 시간 1[s] | 손실 1.73\n",
      "| 에폭 2 |  반복 101 / 351 | 시간 2[s] | 손실 1.73\n",
      "| 에폭 2 |  반복 121 / 351 | 시간 2[s] | 손실 1.72\n",
      "| 에폭 2 |  반복 141 / 351 | 시간 3[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 161 / 351 | 시간 4[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 181 / 351 | 시간 4[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 201 / 351 | 시간 5[s] | 손실 1.70\n",
      "| 에폭 2 |  반복 221 / 351 | 시간 6[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 241 / 351 | 시간 6[s] | 손실 1.70\n",
      "| 에폭 2 |  반복 261 / 351 | 시간 7[s] | 손실 1.69\n",
      "| 에폭 2 |  반복 281 / 351 | 시간 8[s] | 손실 1.69\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 8[s] | 손실 1.69\n",
      "| 에폭 2 |  반복 321 / 351 | 시간 9[s] | 손실 1.68\n",
      "| 에폭 2 |  반복 341 / 351 | 시간 10[s] | 손실 1.67\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 994 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 700 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 400 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 1000\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1544\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 400 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 400 \n",
      "---\n",
      "검증 정확도 0.220%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 3 |  반복 21 / 351 | 시간 0[s] | 손실 1.66\n",
      "| 에폭 3 |  반복 41 / 351 | 시간 1[s] | 손실 1.65\n",
      "| 에폭 3 |  반복 61 / 351 | 시간 1[s] | 손실 1.63\n",
      "| 에폭 3 |  반복 81 / 351 | 시간 2[s] | 손실 1.62\n",
      "| 에폭 3 |  반복 101 / 351 | 시간 3[s] | 손실 1.62\n",
      "| 에폭 3 |  반복 121 / 351 | 시간 3[s] | 손실 1.60\n",
      "| 에폭 3 |  반복 141 / 351 | 시간 4[s] | 손실 1.59\n",
      "| 에폭 3 |  반복 161 / 351 | 시간 5[s] | 손실 1.57\n",
      "| 에폭 3 |  반복 181 / 351 | 시간 5[s] | 손실 1.57\n",
      "| 에폭 3 |  반복 201 / 351 | 시간 6[s] | 손실 1.56\n",
      "| 에폭 3 |  반복 221 / 351 | 시간 6[s] | 손실 1.54\n",
      "| 에폭 3 |  반복 241 / 351 | 시간 7[s] | 손실 1.52\n",
      "| 에폭 3 |  반복 261 / 351 | 시간 7[s] | 손실 1.52\n",
      "| 에폭 3 |  반복 281 / 351 | 시간 8[s] | 손실 1.52\n",
      "| 에폭 3 |  반복 301 / 351 | 시간 9[s] | 손실 1.50\n",
      "| 에폭 3 |  반복 321 / 351 | 시간 9[s] | 손실 1.49\n",
      "| 에폭 3 |  반복 341 / 351 | 시간 10[s] | 손실 1.48\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 108 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1001\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 648 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 138 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 448 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 848 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1011\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1373\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 348 \n",
      "---\n",
      "검증 정확도 0.560%\n",
      "| 에폭 4 |  반복 1 / 351 | 시간 0[s] | 손실 1.47\n",
      "| 에폭 4 |  반복 21 / 351 | 시간 0[s] | 손실 1.46\n",
      "| 에폭 4 |  반복 41 / 351 | 시간 1[s] | 손실 1.44\n",
      "| 에폭 4 |  반복 61 / 351 | 시간 1[s] | 손실 1.43\n",
      "| 에폭 4 |  반복 81 / 351 | 시간 2[s] | 손실 1.42\n",
      "| 에폭 4 |  반복 101 / 351 | 시간 3[s] | 손실 1.41\n",
      "| 에폭 4 |  반복 121 / 351 | 시간 3[s] | 손실 1.40\n",
      "| 에폭 4 |  반복 141 / 351 | 시간 4[s] | 손실 1.40\n",
      "| 에폭 4 |  반복 161 / 351 | 시간 4[s] | 손실 1.38\n",
      "| 에폭 4 |  반복 181 / 351 | 시간 5[s] | 손실 1.38\n",
      "| 에폭 4 |  반복 201 / 351 | 시간 6[s] | 손실 1.37\n",
      "| 에폭 4 |  반복 221 / 351 | 시간 6[s] | 손실 1.35\n",
      "| 에폭 4 |  반복 241 / 351 | 시간 7[s] | 손실 1.33\n",
      "| 에폭 4 |  반복 261 / 351 | 시간 7[s] | 손실 1.33\n",
      "| 에폭 4 |  반복 281 / 351 | 시간 8[s] | 손실 1.33\n",
      "| 에폭 4 |  반복 301 / 351 | 시간 8[s] | 손실 1.32\n",
      "| 에폭 4 |  반복 321 / 351 | 시간 9[s] | 손실 1.31\n",
      "| 에폭 4 |  반복 341 / 351 | 시간 10[s] | 손실 1.30\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 146 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1189\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "O 666 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 162 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 432 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 866 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1002\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1406\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 862 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 202 \n",
      "---\n",
      "검증 정확도 1.060%\n",
      "| 에폭 5 |  반복 1 / 351 | 시간 0[s] | 손실 1.28\n",
      "| 에폭 5 |  반복 21 / 351 | 시간 0[s] | 손실 1.29\n",
      "| 에폭 5 |  반복 41 / 351 | 시간 1[s] | 손실 1.28\n",
      "| 에폭 5 |  반복 61 / 351 | 시간 1[s] | 손실 1.27\n",
      "| 에폭 5 |  반복 81 / 351 | 시간 2[s] | 손실 1.27\n",
      "| 에폭 5 |  반복 101 / 351 | 시간 2[s] | 손실 1.26\n",
      "| 에폭 5 |  반복 121 / 351 | 시간 3[s] | 손실 1.26\n",
      "| 에폭 5 |  반복 141 / 351 | 시간 4[s] | 손실 1.27\n",
      "| 에폭 5 |  반복 161 / 351 | 시간 4[s] | 손실 1.26\n",
      "| 에폭 5 |  반복 181 / 351 | 시간 5[s] | 손실 1.25\n",
      "| 에폭 5 |  반복 201 / 351 | 시간 5[s] | 손실 1.23\n",
      "| 에폭 5 |  반복 221 / 351 | 시간 6[s] | 손실 1.22\n",
      "| 에폭 5 |  반복 241 / 351 | 시간 6[s] | 손실 1.21\n",
      "| 에폭 5 |  반복 261 / 351 | 시간 7[s] | 손실 1.21\n",
      "| 에폭 5 |  반복 281 / 351 | 시간 8[s] | 손실 1.21\n",
      "| 에폭 5 |  반복 301 / 351 | 시간 8[s] | 손실 1.20\n",
      "| 에폭 5 |  반복 321 / 351 | 시간 9[s] | 손실 1.19\n",
      "| 에폭 5 |  반복 341 / 351 | 시간 9[s] | 손실 1.18\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 145 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1168\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 192 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 431 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 895 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1015\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1493\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 891 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 221 \n",
      "---\n",
      "검증 정확도 2.260%\n",
      "| 에폭 6 |  반복 1 / 351 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 6 |  반복 21 / 351 | 시간 0[s] | 손실 1.17\n",
      "| 에폭 6 |  반복 41 / 351 | 시간 1[s] | 손실 1.18\n",
      "| 에폭 6 |  반복 61 / 351 | 시간 1[s] | 손실 1.17\n",
      "| 에폭 6 |  반복 81 / 351 | 시간 2[s] | 손실 1.16\n",
      "| 에폭 6 |  반복 101 / 351 | 시간 3[s] | 손실 1.16\n",
      "| 에폭 6 |  반복 121 / 351 | 시간 3[s] | 손실 1.16\n",
      "| 에폭 6 |  반복 141 / 351 | 시간 4[s] | 손실 1.14\n",
      "| 에폭 6 |  반복 161 / 351 | 시간 5[s] | 손실 1.14\n",
      "| 에폭 6 |  반복 181 / 351 | 시간 5[s] | 손실 1.13\n",
      "| 에폭 6 |  반복 201 / 351 | 시간 6[s] | 손실 1.15\n",
      "| 에폭 6 |  반복 221 / 351 | 시간 7[s] | 손실 1.13\n",
      "| 에폭 6 |  반복 241 / 351 | 시간 7[s] | 손실 1.13\n",
      "| 에폭 6 |  반복 261 / 351 | 시간 8[s] | 손실 1.11\n",
      "| 에폭 6 |  반복 281 / 351 | 시간 9[s] | 손실 1.13\n",
      "| 에폭 6 |  반복 301 / 351 | 시간 9[s] | 손실 1.13\n",
      "| 에폭 6 |  반복 321 / 351 | 시간 10[s] | 손실 1.10\n",
      "| 에폭 6 |  반복 341 / 351 | 시간 11[s] | 손실 1.10\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 166 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1191\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 660 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 199 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 441 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 864 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1011\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1410\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 846 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 260 \n",
      "---\n",
      "검증 정확도 2.800%\n",
      "| 에폭 7 |  반복 1 / 351 | 시간 0[s] | 손실 1.11\n",
      "| 에폭 7 |  반복 21 / 351 | 시간 0[s] | 손실 1.10\n",
      "| 에폭 7 |  반복 41 / 351 | 시간 1[s] | 손실 1.09\n",
      "| 에폭 7 |  반복 61 / 351 | 시간 1[s] | 손실 1.09\n",
      "| 에폭 7 |  반복 81 / 351 | 시간 2[s] | 손실 1.08\n",
      "| 에폭 7 |  반복 101 / 351 | 시간 3[s] | 손실 1.08\n",
      "| 에폭 7 |  반복 121 / 351 | 시간 3[s] | 손실 1.08\n",
      "| 에폭 7 |  반복 141 / 351 | 시간 4[s] | 손실 1.08\n",
      "| 에폭 7 |  반복 161 / 351 | 시간 4[s] | 손실 1.10\n",
      "| 에폭 7 |  반복 181 / 351 | 시간 5[s] | 손실 1.12\n",
      "| 에폭 7 |  반복 201 / 351 | 시간 6[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 221 / 351 | 시간 6[s] | 손실 1.06\n",
      "| 에폭 7 |  반복 241 / 351 | 시간 7[s] | 손실 1.05\n",
      "| 에폭 7 |  반복 261 / 351 | 시간 8[s] | 손실 1.05\n",
      "| 에폭 7 |  반복 281 / 351 | 시간 8[s] | 손실 1.05\n",
      "| 에폭 7 |  반복 301 / 351 | 시간 9[s] | 손실 1.05\n",
      "| 에폭 7 |  반복 321 / 351 | 시간 9[s] | 손실 1.04\n",
      "| 에폭 7 |  반복 341 / 351 | 시간 10[s] | 손실 1.03\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 156 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1131\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 655 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 141 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 412 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 856 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1031\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1374\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "O 864 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 217 \n",
      "---\n",
      "검증 정확도 2.580%\n",
      "| 에폭 8 |  반복 1 / 351 | 시간 0[s] | 손실 1.08\n",
      "| 에폭 8 |  반복 21 / 351 | 시간 0[s] | 손실 1.05\n",
      "| 에폭 8 |  반복 41 / 351 | 시간 1[s] | 손실 1.04\n",
      "| 에폭 8 |  반복 61 / 351 | 시간 2[s] | 손실 1.05\n",
      "| 에폭 8 |  반복 81 / 351 | 시간 2[s] | 손실 1.06\n",
      "| 에폭 8 |  반복 101 / 351 | 시간 3[s] | 손실 1.09\n",
      "| 에폭 8 |  반복 121 / 351 | 시간 4[s] | 손실 1.05\n",
      "| 에폭 8 |  반복 141 / 351 | 시간 4[s] | 손실 1.09\n",
      "| 에폭 8 |  반복 161 / 351 | 시간 5[s] | 손실 1.08\n",
      "| 에폭 8 |  반복 181 / 351 | 시간 6[s] | 손실 1.06\n",
      "| 에폭 8 |  반복 201 / 351 | 시간 6[s] | 손실 1.06\n",
      "| 에폭 8 |  반복 221 / 351 | 시간 7[s] | 손실 1.02\n",
      "| 에폭 8 |  반복 241 / 351 | 시간 8[s] | 손실 1.02\n",
      "| 에폭 8 |  반복 261 / 351 | 시간 8[s] | 손실 1.02\n",
      "| 에폭 8 |  반복 281 / 351 | 시간 9[s] | 손실 1.01\n",
      "| 에폭 8 |  반복 301 / 351 | 시간 10[s] | 손실 1.01\n",
      "| 에폭 8 |  반복 321 / 351 | 시간 10[s] | 손실 1.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3d09560abb0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     trainer.fit(x_train, t_train, max_epoch=1,\n\u001b[1;32m---> 39\u001b[1;33m                 batch_size=batch_size, max_grad=max_grad)\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mcorrect_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\deep-learning-from-scratch-2\\common\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, t, max_epoch, batch_size, max_grad, eval_interval)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[1;31m# 기울기 구해 매개변수 갱신\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\deep-learning-from-scratch-2\\ch07\\seq2seq.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xs, ts)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_ts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\deep-learning-from-scratch-2\\ch07\\seq2seq.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xs, h)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\deep-learning-from-scratch-2\\common\\time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xs)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m             \u001b[0mhs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\deep-learning-from-scratch-2\\common\\time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, h_prev, c_prev)\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\deep-learning-from-scratch-2\\common\\functions.py\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from seq2seq import Seq2seq\n",
    "from peeky_seq2seq import PeekySeq2seq\n",
    "\n",
    "\n",
    "# 데이터셋 읽기\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 반전 여부 설정 =============================================\n",
    "is_reverse = False  # True\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "# ================================================================\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hideen_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 25\n",
    "max_grad = 5.0\n",
    "\n",
    "# 일반 혹은 엿보기(Peeky) 설정 =====================================\n",
    "model = Seq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "# ================================================================\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('검증 정확도 %.3f%%' % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:34:33.620108Z",
     "start_time": "2020-06-20T12:34:33.520375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:34:37.654295Z",
     "start_time": "2020-06-20T12:34:37.636343Z"
    }
   },
   "outputs": [],
   "source": [
    "from common.time_layers import *\n",
    "from seq2seq import Seq2seq, Encoder\n",
    "\n",
    "\n",
    "class PeekyDecoder:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(H + D, 4 * H) / np.sqrt(H + D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H + H, V) / np.sqrt(H + H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.embed = TimeEmbedding(embed_W)\n",
    "        self.lstm = TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True)\n",
    "        self.affine = TimeAffine(affine_W, affine_b)\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in (self.embed, self.lstm, self.affine):\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, xs, h):\n",
    "        N, T = xs.shape\n",
    "        N, H = h.shape\n",
    "\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        out = self.embed.forward(xs)\n",
    "        hs = np.repeat(h, T, axis=0).reshape(N, T, H)\n",
    "        out = np.concatenate((hs, out), axis=2)\n",
    "\n",
    "        out = self.lstm.forward(out)\n",
    "        out = np.concatenate((hs, out), axis=2)\n",
    "\n",
    "        score = self.affine.forward(out)\n",
    "        self.cache = H\n",
    "        return score\n",
    "\n",
    "    def backward(self, dscore):\n",
    "        H = self.cache\n",
    "\n",
    "        dout = self.affine.backward(dscore)\n",
    "        dout, dhs0 = dout[:, :, H:], dout[:, :, :H]\n",
    "        dout = self.lstm.backward(dout)\n",
    "        dembed, dhs1 = dout[:, :, H:], dout[:, :, :H]\n",
    "        self.embed.backward(dembed)\n",
    "\n",
    "        dhs = dhs0 + dhs1\n",
    "        dh = self.lstm.dh + np.sum(dhs, axis=1)\n",
    "        return dh\n",
    "\n",
    "    def generate(self, h, start_id, sample_size):\n",
    "        sampled = []\n",
    "        char_id = start_id\n",
    "        self.lstm.set_state(h)\n",
    "\n",
    "        H = h.shape[1]\n",
    "        peeky_h = h.reshape(1, 1, H)\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array([char_id]).reshape((1, 1))\n",
    "            out = self.embed.forward(x)\n",
    "\n",
    "            out = np.concatenate((peeky_h, out), axis=2)\n",
    "            out = self.lstm.forward(out)\n",
    "            out = np.concatenate((peeky_h, out), axis=2)\n",
    "            score = self.affine.forward(out)\n",
    "\n",
    "            char_id = np.argmax(score.flatten())\n",
    "            sampled.append(char_id)\n",
    "\n",
    "        return sampled\n",
    "\n",
    "\n",
    "class PeekySeq2seq(Seq2seq):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.encoder = Encoder(V, D, H)\n",
    "        self.decoder = PeekyDecoder(V, D, H)\n",
    "        self.softmax = TimeSoftmaxWithLoss()\n",
    "\n",
    "        self.params = self.encoder.params + self.decoder.params\n",
    "        self.grads = self.encoder.grads + self.decoder.grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:37:14.448464Z",
     "start_time": "2020-06-20T12:34:38.946369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 351 | 시간 0[s] | 손실 2.57\n",
      "| 에폭 1 |  반복 21 / 351 | 시간 0[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 41 / 351 | 시간 1[s] | 손실 2.20\n",
      "| 에폭 1 |  반복 61 / 351 | 시간 1[s] | 손실 1.96\n",
      "| 에폭 1 |  반복 81 / 351 | 시간 2[s] | 손실 1.84\n",
      "| 에폭 1 |  반복 101 / 351 | 시간 2[s] | 손실 1.80\n",
      "| 에폭 1 |  반복 121 / 351 | 시간 3[s] | 손실 1.79\n",
      "| 에폭 1 |  반복 141 / 351 | 시간 3[s] | 손실 1.77\n",
      "| 에폭 1 |  반복 161 / 351 | 시간 4[s] | 손실 1.77\n",
      "| 에폭 1 |  반복 181 / 351 | 시간 5[s] | 손실 1.76\n",
      "| 에폭 1 |  반복 201 / 351 | 시간 5[s] | 손실 1.76\n",
      "| 에폭 1 |  반복 221 / 351 | 시간 6[s] | 손실 1.75\n",
      "| 에폭 1 |  반복 241 / 351 | 시간 6[s] | 손실 1.76\n",
      "| 에폭 1 |  반복 261 / 351 | 시간 7[s] | 손실 1.75\n",
      "| 에폭 1 |  반복 281 / 351 | 시간 8[s] | 손실 1.74\n",
      "| 에폭 1 |  반복 301 / 351 | 시간 8[s] | 손실 1.73\n",
      "| 에폭 1 |  반복 321 / 351 | 시간 9[s] | 손실 1.73\n",
      "| 에폭 1 |  반복 341 / 351 | 시간 10[s] | 손실 1.73\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 107 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1011\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 103 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 101 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 103 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 1023\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1023\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1011\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 103 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 323 \n",
      "---\n",
      "검증 정확도 0.180%\n",
      "| 에폭 2 |  반복 1 / 351 | 시간 0[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 21 / 351 | 시간 0[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 41 / 351 | 시간 1[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 61 / 351 | 시간 1[s] | 손실 1.70\n",
      "| 에폭 2 |  반복 81 / 351 | 시간 2[s] | 손실 1.70\n",
      "| 에폭 2 |  반복 101 / 351 | 시간 3[s] | 손실 1.70\n",
      "| 에폭 2 |  반복 121 / 351 | 시간 3[s] | 손실 1.71\n",
      "| 에폭 2 |  반복 141 / 351 | 시간 4[s] | 손실 1.70\n",
      "| 에폭 2 |  반복 161 / 351 | 시간 4[s] | 손실 1.69\n",
      "| 에폭 2 |  반복 181 / 351 | 시간 5[s] | 손실 1.69\n",
      "| 에폭 2 |  반복 201 / 351 | 시간 6[s] | 손실 1.68\n",
      "| 에폭 2 |  반복 221 / 351 | 시간 6[s] | 손실 1.68\n",
      "| 에폭 2 |  반복 241 / 351 | 시간 7[s] | 손실 1.69\n",
      "| 에폭 2 |  반복 261 / 351 | 시간 7[s] | 손실 1.68\n",
      "| 에폭 2 |  반복 281 / 351 | 시간 8[s] | 손실 1.68\n",
      "| 에폭 2 |  반복 301 / 351 | 시간 9[s] | 손실 1.66\n",
      "| 에폭 2 |  반복 321 / 351 | 시간 9[s] | 손실 1.66\n",
      "| 에폭 2 |  반복 341 / 351 | 시간 10[s] | 손실 1.65\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 100 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1000\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 700 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 100 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 400 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 1009\n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1000\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1240\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 400 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 280 \n",
      "---\n",
      "검증 정확도 0.220%\n",
      "| 에폭 3 |  반복 1 / 351 | 시간 0[s] | 손실 1.65\n",
      "| 에폭 3 |  반복 21 / 351 | 시간 0[s] | 손실 1.64\n",
      "| 에폭 3 |  반복 41 / 351 | 시간 1[s] | 손실 1.62\n",
      "| 에폭 3 |  반복 61 / 351 | 시간 1[s] | 손실 1.60\n",
      "| 에폭 3 |  반복 81 / 351 | 시간 2[s] | 손실 1.58\n",
      "| 에폭 3 |  반복 101 / 351 | 시간 3[s] | 손실 1.56\n",
      "| 에폭 3 |  반복 121 / 351 | 시간 4[s] | 손실 1.54\n",
      "| 에폭 3 |  반복 141 / 351 | 시간 5[s] | 손실 1.53\n",
      "| 에폭 3 |  반복 161 / 351 | 시간 6[s] | 손실 1.52\n",
      "| 에폭 3 |  반복 181 / 351 | 시간 7[s] | 손실 1.49\n",
      "| 에폭 3 |  반복 201 / 351 | 시간 8[s] | 손실 1.48\n",
      "| 에폭 3 |  반복 221 / 351 | 시간 9[s] | 손실 1.45\n",
      "| 에폭 3 |  반복 241 / 351 | 시간 10[s] | 손실 1.43\n",
      "| 에폭 3 |  반복 261 / 351 | 시간 11[s] | 손실 1.42\n",
      "| 에폭 3 |  반복 281 / 351 | 시간 12[s] | 손실 1.40\n",
      "| 에폭 3 |  반복 301 / 351 | 시간 13[s] | 손실 1.38\n",
      "| 에폭 3 |  반복 321 / 351 | 시간 14[s] | 손실 1.36\n",
      "| 에폭 3 |  반복 341 / 351 | 시간 15[s] | 손실 1.35\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 152 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1194\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 744 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 151 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 441 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 855 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1006\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1444\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 814 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 291 \n",
      "---\n",
      "검증 정확도 1.400%\n",
      "| 에폭 4 |  반복 1 / 351 | 시간 0[s] | 손실 1.33\n",
      "| 에폭 4 |  반복 21 / 351 | 시간 0[s] | 손실 1.33\n",
      "| 에폭 4 |  반복 41 / 351 | 시간 1[s] | 손실 1.31\n",
      "| 에폭 4 |  반복 61 / 351 | 시간 2[s] | 손실 1.31\n",
      "| 에폭 4 |  반복 81 / 351 | 시간 2[s] | 손실 1.29\n",
      "| 에폭 4 |  반복 101 / 351 | 시간 3[s] | 손실 1.29\n",
      "| 에폭 4 |  반복 121 / 351 | 시간 4[s] | 손실 1.27\n",
      "| 에폭 4 |  반복 141 / 351 | 시간 5[s] | 손실 1.26\n",
      "| 에폭 4 |  반복 161 / 351 | 시간 5[s] | 손실 1.25\n",
      "| 에폭 4 |  반복 181 / 351 | 시간 6[s] | 손실 1.24\n",
      "| 에폭 4 |  반복 201 / 351 | 시간 7[s] | 손실 1.23\n",
      "| 에폭 4 |  반복 221 / 351 | 시간 7[s] | 손실 1.22\n",
      "| 에폭 4 |  반복 241 / 351 | 시간 8[s] | 손실 1.21\n",
      "| 에폭 4 |  반복 261 / 351 | 시간 9[s] | 손실 1.21\n",
      "| 에폭 4 |  반복 281 / 351 | 시간 10[s] | 손실 1.20\n",
      "| 에폭 4 |  반복 301 / 351 | 시간 10[s] | 손실 1.17\n",
      "| 에폭 4 |  반복 321 / 351 | 시간 11[s] | 손실 1.17\n",
      "| 에폭 4 |  반복 341 / 351 | 시간 12[s] | 손실 1.16\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 168 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1180\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 633 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 153 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 403 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 853 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1027\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1483\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 888 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 283 \n",
      "---\n",
      "검증 정확도 3.000%\n",
      "| 에폭 5 |  반복 1 / 351 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 5 |  반복 21 / 351 | 시간 0[s] | 손실 1.14\n",
      "| 에폭 5 |  반복 41 / 351 | 시간 1[s] | 손실 1.14\n",
      "| 에폭 5 |  반복 61 / 351 | 시간 2[s] | 손실 1.13\n",
      "| 에폭 5 |  반복 81 / 351 | 시간 2[s] | 손실 1.11\n",
      "| 에폭 5 |  반복 101 / 351 | 시간 3[s] | 손실 1.10\n",
      "| 에폭 5 |  반복 121 / 351 | 시간 3[s] | 손실 1.09\n",
      "| 에폭 5 |  반복 141 / 351 | 시간 4[s] | 손실 1.09\n",
      "| 에폭 5 |  반복 161 / 351 | 시간 5[s] | 손실 1.08\n",
      "| 에폭 5 |  반복 181 / 351 | 시간 5[s] | 손실 1.06\n",
      "| 에폭 5 |  반복 201 / 351 | 시간 6[s] | 손실 1.05\n",
      "| 에폭 5 |  반복 221 / 351 | 시간 7[s] | 손실 1.05\n",
      "| 에폭 5 |  반복 241 / 351 | 시간 7[s] | 손실 1.04\n",
      "| 에폭 5 |  반복 261 / 351 | 시간 8[s] | 손실 1.04\n",
      "| 에폭 5 |  반복 281 / 351 | 시간 9[s] | 손실 1.03\n",
      "| 에폭 5 |  반복 301 / 351 | 시간 9[s] | 손실 1.01\n",
      "| 에폭 5 |  반복 321 / 351 | 시간 10[s] | 손실 1.01\n",
      "| 에폭 5 |  반복 341 / 351 | 시간 11[s] | 손실 1.00\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 160 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1128\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 650 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "X 404 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 851 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1025\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1400\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 870 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 209 \n",
      "---\n",
      "검증 정확도 4.920%\n",
      "| 에폭 6 |  반복 1 / 351 | 시간 0[s] | 손실 1.00\n",
      "| 에폭 6 |  반복 21 / 351 | 시간 0[s] | 손실 0.98\n",
      "| 에폭 6 |  반복 41 / 351 | 시간 1[s] | 손실 0.97\n",
      "| 에폭 6 |  반복 61 / 351 | 시간 2[s] | 손실 0.97\n",
      "| 에폭 6 |  반복 81 / 351 | 시간 2[s] | 손실 0.96\n",
      "| 에폭 6 |  반복 101 / 351 | 시간 3[s] | 손실 0.95\n",
      "| 에폭 6 |  반복 121 / 351 | 시간 3[s] | 손실 0.95\n",
      "| 에폭 6 |  반복 141 / 351 | 시간 4[s] | 손실 0.95\n",
      "| 에폭 6 |  반복 161 / 351 | 시간 5[s] | 손실 0.93\n",
      "| 에폭 6 |  반복 181 / 351 | 시간 6[s] | 손실 0.92\n",
      "| 에폭 6 |  반복 201 / 351 | 시간 6[s] | 손실 0.92\n",
      "| 에폭 6 |  반복 221 / 351 | 시간 7[s] | 손실 0.92\n",
      "| 에폭 6 |  반복 241 / 351 | 시간 8[s] | 손실 0.91\n",
      "| 에폭 6 |  반복 261 / 351 | 시간 8[s] | 손실 0.90\n",
      "| 에폭 6 |  반복 281 / 351 | 시간 9[s] | 손실 0.89\n",
      "| 에폭 6 |  반복 301 / 351 | 시간 10[s] | 손실 0.89\n",
      "| 에폭 6 |  반복 321 / 351 | 시간 10[s] | 손실 0.89\n",
      "| 에폭 6 |  반복 341 / 351 | 시간 11[s] | 손실 0.88\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 165 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1117\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 661 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 848 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1027\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1400\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 860 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 233 \n",
      "---\n",
      "검증 정확도 8.280%\n",
      "| 에폭 7 |  반복 1 / 351 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 7 |  반복 21 / 351 | 시간 0[s] | 손실 0.87\n",
      "| 에폭 7 |  반복 41 / 351 | 시간 1[s] | 손실 0.87\n",
      "| 에폭 7 |  반복 61 / 351 | 시간 2[s] | 손실 0.86\n",
      "| 에폭 7 |  반복 81 / 351 | 시간 2[s] | 손실 0.86\n",
      "| 에폭 7 |  반복 101 / 351 | 시간 3[s] | 손실 0.84\n",
      "| 에폭 7 |  반복 121 / 351 | 시간 4[s] | 손실 0.84\n",
      "| 에폭 7 |  반복 141 / 351 | 시간 4[s] | 손실 0.85\n",
      "| 에폭 7 |  반복 161 / 351 | 시간 5[s] | 손실 0.83\n",
      "| 에폭 7 |  반복 181 / 351 | 시간 6[s] | 손실 0.82\n",
      "| 에폭 7 |  반복 201 / 351 | 시간 6[s] | 손실 0.82\n",
      "| 에폭 7 |  반복 221 / 351 | 시간 7[s] | 손실 0.82\n",
      "| 에폭 7 |  반복 241 / 351 | 시간 8[s] | 손실 0.81\n",
      "| 에폭 7 |  반복 261 / 351 | 시간 8[s] | 손실 0.82\n",
      "| 에폭 7 |  반복 281 / 351 | 시간 9[s] | 손실 0.81\n",
      "| 에폭 7 |  반복 301 / 351 | 시간 10[s] | 손실 0.79\n",
      "| 에폭 7 |  반복 321 / 351 | 시간 10[s] | 손실 0.79\n",
      "| 에폭 7 |  반복 341 / 351 | 시간 11[s] | 손실 0.79\n",
      "Q 77+85  \n",
      "T 162 \n",
      "X 165 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1108\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 848 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1068\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1460\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 868 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 240 \n",
      "---\n",
      "검증 정확도 9.220%\n",
      "| 에폭 8 |  반복 1 / 351 | 시간 0[s] | 손실 0.81\n",
      "| 에폭 8 |  반복 21 / 351 | 시간 0[s] | 손실 0.77\n",
      "| 에폭 8 |  반복 41 / 351 | 시간 1[s] | 손실 0.77\n",
      "| 에폭 8 |  반복 61 / 351 | 시간 2[s] | 손실 0.78\n",
      "| 에폭 8 |  반복 81 / 351 | 시간 2[s] | 손실 0.77\n",
      "| 에폭 8 |  반복 101 / 351 | 시간 3[s] | 손실 0.76\n",
      "| 에폭 8 |  반복 121 / 351 | 시간 4[s] | 손실 0.76\n",
      "| 에폭 8 |  반복 141 / 351 | 시간 4[s] | 손실 0.75\n",
      "| 에폭 8 |  반복 161 / 351 | 시간 5[s] | 손실 0.75\n",
      "| 에폭 8 |  반복 181 / 351 | 시간 6[s] | 손실 0.75\n",
      "| 에폭 8 |  반복 201 / 351 | 시간 7[s] | 손실 0.75\n",
      "| 에폭 8 |  반복 221 / 351 | 시간 7[s] | 손실 0.74\n",
      "| 에폭 8 |  반복 241 / 351 | 시간 8[s] | 손실 0.72\n",
      "| 에폭 8 |  반복 261 / 351 | 시간 9[s] | 손실 0.72\n",
      "| 에폭 8 |  반복 281 / 351 | 시간 10[s] | 손실 0.74\n",
      "| 에폭 8 |  반복 301 / 351 | 시간 10[s] | 손실 0.74\n",
      "| 에폭 8 |  반복 321 / 351 | 시간 11[s] | 손실 0.73\n",
      "| 에폭 8 |  반복 341 / 351 | 시간 12[s] | 손실 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q 77+85  \n",
      "T 162 \n",
      "X 164 \n",
      "---\n",
      "Q 975+164\n",
      "T 1139\n",
      "X 1137\n",
      "---\n",
      "Q 582+84 \n",
      "T 666 \n",
      "X 665 \n",
      "---\n",
      "Q 8+155  \n",
      "T 163 \n",
      "X 160 \n",
      "---\n",
      "Q 367+55 \n",
      "T 422 \n",
      "O 422 \n",
      "---\n",
      "Q 600+257\n",
      "T 857 \n",
      "X 849 \n",
      "---\n",
      "Q 761+292\n",
      "T 1053\n",
      "X 1037\n",
      "---\n",
      "Q 830+597\n",
      "T 1427\n",
      "X 1437\n",
      "---\n",
      "Q 26+838 \n",
      "T 864 \n",
      "X 869 \n",
      "---\n",
      "Q 143+93 \n",
      "T 236 \n",
      "X 231 \n",
      "---\n",
      "검증 정확도 12.480%\n",
      "| 에폭 9 |  반복 1 / 351 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 9 |  반복 21 / 351 | 시간 0[s] | 손실 0.70\n",
      "| 에폭 9 |  반복 41 / 351 | 시간 1[s] | 손실 0.70\n",
      "| 에폭 9 |  반복 61 / 351 | 시간 2[s] | 손실 0.70\n",
      "| 에폭 9 |  반복 81 / 351 | 시간 2[s] | 손실 0.70\n",
      "| 에폭 9 |  반복 101 / 351 | 시간 3[s] | 손실 0.69\n",
      "| 에폭 9 |  반복 121 / 351 | 시간 4[s] | 손실 0.69\n",
      "| 에폭 9 |  반복 141 / 351 | 시간 4[s] | 손실 0.68\n",
      "| 에폭 9 |  반복 161 / 351 | 시간 5[s] | 손실 0.68\n",
      "| 에폭 9 |  반복 181 / 351 | 시간 6[s] | 손실 0.67\n",
      "| 에폭 9 |  반복 201 / 351 | 시간 6[s] | 손실 0.68\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-387a60bfe27a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     trainer.fit(x_train, t_train, max_epoch=1,\n\u001b[1;32m---> 38\u001b[1;33m                 batch_size=batch_size, max_grad=max_grad)\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mcorrect_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\deep-learning-from-scratch-2\\common\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, t, max_epoch, batch_size, max_grad, eval_interval)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[1;31m# 기울기 구해 매개변수 갱신\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\deep-learning-from-scratch-2\\ch07\\seq2seq.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xs, ts)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mdecoder_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_ts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_ts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\deep-learning-from-scratch-2\\ch07\\seq2seq.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xs)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mhs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\deep-learning-from-scratch-2\\common\\time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, xs)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m             \u001b[0mhs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\deep-learning-from-scratch-2\\common\\time_layers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, h_prev, c_prev)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\deep-learning-from-scratch-2\\common\\functions.py\u001b[0m in \u001b[0;36msigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from seq2seq import Seq2seq\n",
    "from peeky_seq2seq import PeekySeq2seq\n",
    "\n",
    "\n",
    "# 데이터셋 읽기\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt')\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "# 입력 반전 여부 설정 =============================================\n",
    "is_reverse = False  # True\n",
    "if is_reverse:\n",
    "    x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n",
    "# ================================================================\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hideen_size = 128\n",
    "batch_size = 128\n",
    "max_epoch = 25\n",
    "max_grad = 5.0\n",
    "\n",
    "# 일반 혹은 엿보기(Peeky) 설정 =====================================\n",
    "model = PeekySeq2seq(vocab_size, wordvec_size, hideen_size)\n",
    "# ================================================================\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1,\n",
    "                batch_size=batch_size, max_grad=max_grad)\n",
    "\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct,\n",
    "                                    id_to_char, verbose, is_reverse)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print('검증 정확도 %.3f%%' % (acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T12:37:17.240678Z",
     "start_time": "2020-06-20T12:37:17.139947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "x = np.arange(len(acc_list))\n",
    "plt.plot(x, acc_list, marker='o')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
